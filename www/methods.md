### Original method
The method used by Grimm and colleagues starts with the premise that an underlying diffusion curves exists that is consistent with Rogers theory of diffusion.
Following on from this, the approach follows these steps:
	
1. Expert elicitation methods were used to identify three points on the underlying diffusion curve, each with its own associated probability distribution.  These points are:
	- $m$, the maximum level of diffusion
	- $N1$, the number of adoptions in the first year after the technology is introduced
	- $t'$, the number of years after which the rate of diffusion starts to decline
	

  Within the particular application described by Grimm, three experts were approached, with gamma distributions being fitted to their elicited values.  The probability distributions for each parameter were combined using linear mathematical pooling 
	
2. An observation from each of the probability distributions describing $m$, $N1$ and $t'$ and  was taken at random, and a diffusion curve fitted to the data using Excel solver.  The diffusion curve is described by the Bass Model, which is calculated using three different parameters.  The parameter values and associated curve are saved.
	
3. The sampling and fitting process was repeated 1,000 times to produce probability distributions around the three Bass parameters.

4. The mean value for the three Bass parameters is then calculated together with their associated diffusion curve.  $95\%$ confidence intervals were estimated by combining the $97.5\%$ and $2.5\%$ values from the three Bass parameter distributions.

For a detailed description of the original method and case study, see:
- Grimm SE, Stevens JW, Dixon S.  Estimating Future Health Technology Diffusion Using Expert Beliefs Calibrated to an Established Diffusion Model.  Value Health. 2018 Aug;21(8):944-950. doi: 10.1016/j.jval.2018.01.010.


### Amendments to the original method
In the development process of our DCG, we identified a number of improvements to the process.  These were:

- Alternative pooling method
  Whilst the original method used linear mathematical pooling, within the DCG tool we give the user the choice of linear pooling and a mixture distribution.  For the linear combination we repeatedly sample values from every expert’s inputted distribution, then calculate the mean of the values for m, N1 and t’.  For the mixture distribution, we repeatedly sample experts, from whom we take a sample of m, N1 and t’ from their elicited distribution; this is a model averaging approach. 

- Alternative fitting algorithm
  The original formulation used Excel solver to identify values of p and q, that minimise the sum of the squared errors between the observed (elicited) values for $m$, $N1$ and $t'$, and the fitted values that are generated via the Satoh reformulation of the Bass model.  In addition, in order to reduce computational time, p and q were constrained such that $0<p<0.2$ and $0<q<2.5$ (which were informed by a meta-analysis of previously published values).
Within the alternative formulation used here, the “constrOptim” command in R is used to minimise the Return Distance, $\sqrt{(N1 - \widehat{N1})^2 + (t'-\widehat{t'})^2}$, between the observed (elicited) values for $N1$ and $t'$, and the values generated by the Bass model closed form solutions:
	
	$$N1=m(\frac{1-e^{-(p+q)}}{1+\frac{q}{p}e^{-(p+q)}})$$
	
	$$t'=\frac{log(q) - log(p)}{p+q}$$

	
In addition, we constrain the algorithm used by **constrOptim** to values of p and q where $q>p>0$; this is required to ensure an s-shaped diffusion curve.
In summary, the differences are:
	1. Use of the (continuous) Bass model as opposed to the (discrete) Satoh formulation
	2. Different optimisation algorithm
	3. The use of a constraint predicated on theory, as opposed to a constraint predicated on computational speed.


### Alternative method for calculating diffusion curves for centiles
The original formulation used the $97.5\%$ and $2.5\%$ values from the three Bass parameter distributions to approximate associated diffusion curves.  However, as highlighted in the paper, such an approach does not guarantee that $95\%$ of the sampled diffusion curves’ values are within these bounds for any time point.  The correct, but more computationally intensive, method for generating a diffusion curve for any given centile is to identify the appropriate value from the set of curves generated by the resampling-fitting process, for each time point.  It is this method that is used within the  *DCG* tool.

### Future developments
As well as the amendments to the original method described above, further refinements of the methodology are being considered, including how to elicit and incorporate correlations between $m$, $N1$ and $t'$.
If you are interested in this, or any other developments to this method, please contact us.
